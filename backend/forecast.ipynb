{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec233825",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installation\n",
    "%pip install fastapi uvicorn nest-asyncio   # API\n",
    "%pip install numpy                          # Efficient data handling\n",
    "%pip install pandas                         # Efficient date handling & aggregation\n",
    "%pip install python-dotenv                  # .env => extracting hidden info\n",
    "%pip install requests                       # Performing API calls\n",
    "%pip install statsmodels                   # Optimized Parameter Generation\n",
    "\n",
    "## Imports\n",
    "from fastapi import FastAPI, Cookie, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from typing import Annotated\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from enum import Enum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e244cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "load_dotenv()\n",
    "\n",
    "## Global Variables\n",
    "BACKEND_URL = os.getenv(\"BACKEND_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\", \"http://localhost:3000\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31169dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA Parameters\n",
    "p = 1       # 1st Order Non-Seasonal AR Component\n",
    "d = 1       # 1st Order Non-Seasonal I Component\n",
    "q = 1       # 1st Order Non-Seasonal MA Component\n",
    "P = 1       # 1st Order Seasonal AR Component\n",
    "D = 1       # 1st Order Seasonal I Component\n",
    "Q = 1       # 1st Order Seasonal MA Component\n",
    "s = 52      # Weekly\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess Data\n",
    "def preprocess_order_data(order_data):\n",
    "    order_df = pd.DataFrame(order_data)\n",
    "    order_df['order_time'] = order_df['order_time'].apply(lambda date_time : pd.to_datetime(date_time, utc=True).normalize())\n",
    "    \n",
    "    num_orders_df = order_df.groupby('order_time', group_keys=True)['cost'].count().reset_index().rename(columns={'cost': 'num_orders'})\n",
    "    first_time_orders_df = order_df[order_df['is_first_order']]\n",
    "    num_first_time_orders_df = first_time_orders_df.groupby('order_time', group_keys=True)['cost'].count().reset_index().rename(columns={'cost': 'num_first_time_orders'})\n",
    "    revenue_df = order_df.groupby('order_time', group_keys=True)['cost'].sum().reset_index().rename(columns={'cost': 'revenue'})\n",
    "    \n",
    "    return dict(revenue_df=revenue_df, order_df=num_orders_df, first_time_consumer_df=num_first_time_orders_df)\n",
    "\n",
    "def preprocess_visit_data(visit_data): \n",
    "    visit_df = pd.DataFrame(visit_data)\n",
    "    visit_df['visit_time'] = visit_df['visit_time'].apply(lambda date_time : pd.to_datetime(date_time, utc=True).normalize())\n",
    "    \n",
    "    num_visits_df = visit_df.groupby('visit_time', group_keys=True)['restaurant_id'].count().reset_index().rename(columns={'restaurant_id': 'num_visits'})\n",
    "    \n",
    "    return num_visits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for retrieving data from DB\n",
    "def get_restaurant_data_helper(path, cookies):\n",
    "    response = requests.get(path, cookies=cookies)\n",
    "    if not response.ok:\n",
    "        raise HTTPException(status_code=424, detail=\"Failed to pull restaurant data from DB\")\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "# TODO: Put data (num orders, total revenue, num first-time orders, num site visits) for a given restaurant into buckets\n",
    "def get_restaurant_data(connect_sid, restaurant_id):\n",
    "    cookies = {\n",
    "        \"connect.sid\": connect_sid\n",
    "    }\n",
    "    \n",
    "    # Get data\n",
    "    order_data = get_restaurant_data_helper(f\"{BACKEND_URL}/analytics/orders/{restaurant_id}\", cookies)\n",
    "    visit_data = get_restaurant_data_helper(f\"{BACKEND_URL}/analytics/visits/{restaurant_id}\", cookies)\n",
    "    \n",
    "    revenue_df, order_df, first_time_consumer_df = preprocess_order_data(order_data)\n",
    "    visit_df = preprocess_visit_data(visit_data)\n",
    "    \n",
    "    return dict(revenue_df=revenue_df, order_df=order_df, visit_df=visit_df, first_time_consumer_df=first_time_consumer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d45e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply differencing\n",
    "# Credit: https://otexts.com/fpp2/stationarity.html\n",
    "def differencing(arr, lag = 1, repeat = 1):\n",
    "    differenced_arr = np.copy(arr)\n",
    "    for i in range(repeat):\n",
    "        differenced_arr = differenced_arr[lag:] - differenced_arr[:lag]\n",
    "    return differenced_arr\n",
    "\n",
    "# Apply undifferencing\n",
    "# Credit: https://stackoverflow.com/questions/72700812/how-to-inverse-differencing-on-future-forecasted-result\n",
    "def revert_differencing(original_arr, differenced_arr, lag = 1, repeat = 1):\n",
    "    inverted_diff_arr = np.copy(differenced_arr)\n",
    "    for i in range(repeat):\n",
    "        inverted_diff_arr = np.r_[original_arr[-lag:], differenced_arr].cumsum()\n",
    "    return inverted_diff_arr[-len(differenced_arr):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform polynomial multiplication (essentially performing discrete convolution)\n",
    "def polynomial_mul(poly_a, poly_b):\n",
    "    product_len = len(poly_a) + len(poly_b) - 1\n",
    "    product_poly = np.zeros(product_len, dtype=float)\n",
    "    for i in range(len(poly_a)):\n",
    "        for j in range(len(poly_b)):\n",
    "            product_poly[i + j] += poly_a[i] * poly_b[j]     \n",
    "    return product_poly\n",
    "\n",
    "# Using seasonal and non-seasonal coefficients, generates the polynomial upon application of both seasonal/non-seasonal for one of: {MA, AR}\n",
    "def generate_seasonal_n_nonseasonal_poly(seasonal_coeff, nonseasonal_coeff, is_positive):\n",
    "    # TODO: Use s from above\n",
    "    # Nonseasonal Polynomial w/ Lag Coefficients\n",
    "    nonseasonal_poly = np.zeros(len(nonseasonal_coeff) + 1) \n",
    "    nonseasonal_poly[0] = 1\n",
    "    nonseasonal_poly[1:] = np.array(nonseasonal_coeff) if is_positive else -np.array(nonseasonal_coeff)\n",
    "    \n",
    "    # Seasonal Polynomial w/ Lag Coefficients\n",
    "    seasonal_poly = np.zeros((len(seasonal_coeff) * s) + 1)\n",
    "    seasonal_poly[0] = 1\n",
    "    for i in range(s):\n",
    "        seasonal_poly[s*i] = seasonal_coeff[i] if is_positive else -seasonal_coeff[i]\n",
    "        \n",
    "    # Generate Product Polynomial\n",
    "    product_poly = polynomial_mul(nonseasonal_poly, seasonal_poly)\n",
    "    \n",
    "    return product_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform parameter generation from scratch\n",
    "# NOTE: Implementing this from scratch would require using Hannanâ€“Rissanen and Maximum Likelihood Estimation (MLE) with a Kalman filter and additional optimizers, which would\n",
    "# add an extreme and highly unrealistic level of complexity (due to the very difficult math involved)\n",
    "# NOTE: This ONLY uses model parameters - everything else is being done entirely from scratch\n",
    "\n",
    "def get_sarima_params(data):\n",
    "    # TODO: Test the output of res.params to be certain this will work\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    model = SARIMAX(data, order=(p,d,q), seasonal_order=(P,D,Q,s))\n",
    "    res = model.fit(disp=False)\n",
    "    params = res.params\n",
    "    resid = res.resid\n",
    "    \n",
    "    phi1   = params[0]\n",
    "    theta1 = params[1]\n",
    "    Phi1   = params[2]\n",
    "    Theta1 = params[3]\n",
    "\n",
    "    return dict(phi1=phi1, theta1=theta1, Phi1=Phi1, Theta1=Theta1, resid=resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_logic(data, num_forecast_weeks=1):\n",
    "    # Retrieve SARIMA parameters\n",
    "    params = get_sarima_params(data)\n",
    "    phi1, Phi1, theta1, Theta1, resid = params['phi1'], params['Phi1'], params['theta1'], params['Theta1'], params['resid']\n",
    "    \n",
    "    # Apply trend differencing\n",
    "    differenced_trend = differencing(data, lag=1, repeat=d)\n",
    "    # Apply seasonal differencing\n",
    "    differenced_all = differencing(differenced_trend, lag=s, repeat=D)\n",
    "    \n",
    "    # Generate shocks\n",
    "    shocks = np.array(resid)\n",
    "    \n",
    "    # Generate AR & MA polynomials\n",
    "    ar_polys = generate_seasonal_n_nonseasonal_poly([Phi1], [phi1], is_positive=False)\n",
    "    ma_polys = generate_seasonal_n_nonseasonal_poly([Theta1], [theta1], is_positive=True)\n",
    "    forecast_arr = []\n",
    "    \n",
    "    # Apply forecasting\n",
    "    for i in range(num_forecast_weeks):\n",
    "        ar = np.dot(ar_polys, differenced_all[-len(ar_polys):][::-1])\n",
    "        ma = np.dot(ma_polys, shocks[-len(ma_polys):][::-1])\n",
    "        \n",
    "        forecast = ar - ma\n",
    "        differenced_all = np.append(differenced_all, [forecast])\n",
    "        shocks = np.append(shocks, [0.0]) # SARIMA takes expectation & assumes no future error\n",
    "        forecast_arr.append(forecast)\n",
    "    \n",
    "    # Invert differencing\n",
    "    forecast_data_inverted_seasonal = revert_differencing(differenced_all, forecast_arr, lag=s, repeat=D)\n",
    "    forecast_data_inverted_all = revert_differencing(data, forecast_data_inverted_seasonal, lag=1, repeat=d)\n",
    "    \n",
    "    return forecast_data_inverted_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Given limited data, will only be used to forecast next week's KPI figures\n",
    "@app.get(\"/forecast/{restaurant_id}\")\n",
    "def forecast(restaurant_id: int, connect_sid: Annotated[str | None, Cookie(alias=\"connect.sid\")] = None):\n",
    "    # NOTE: FastAPI Cookie handling from here: https://fastapi.tiangolo.com/tutorial/cookie-params/#import-cookie\n",
    "    if connect_sid is None:\n",
    "        raise HTTPException(status_code=401, detail=\"Consumer session cookie not found\")\n",
    "    \n",
    "    # Get data\n",
    "    revenue_data, order_data, visit_data, first_time_consumer_data = get_restaurant_data(connect_sid, restaurant_id)\n",
    "    return\n",
    "    \n",
    "    # Perform forecasting\n",
    "    next_week_revenue = forecast_logic(revenue_data, num_forecast_weeks=1)\n",
    "    next_week_orders = forecast_logic(order_data, num_forecast_weeks=1)\n",
    "    next_week_site_visits = forecast_logic(visit_data, num_forecast_weeks=1)\n",
    "    next_week_first_time_consumers = forecast_logic(first_time_consumer_data, num_forecast_weeks=1)\n",
    "    \n",
    "    return JSONResponse({\"revenue\": next_week_revenue, \"orders\": next_week_orders, \"visits\": next_week_site_visits, \"first_time_consumers\": next_week_first_time_consumers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get FastAPI Server Online\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
