{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ab7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installation\n",
    "%pip install fastapi uvicorn    # API\n",
    "%pip install numpy              # Efficient data handling\n",
    "%pip install python-dotenv      # .env => extracting hidden info\n",
    "%pip install requests           # Performing API calls\n",
    "\n",
    "## Imports\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "load_dotenv()\n",
    "\n",
    "## Global Variables\n",
    "BACKEND_URL = os.getenv(\"BACKEND_URL\")\n",
    "class ConsumerField(Enum):\n",
    "    VISITS = 1\n",
    "    ORDERS = 2\n",
    "    FAVORITED = 3\n",
    "    FRIENDS = 4\n",
    "    ALL = 5\n",
    "\n",
    "categories = [ # Based off of prisma schema categories enum\n",
    "    \"asian\",\n",
    "    \"bakery\",\n",
    "    \"barfood\",\n",
    "    \"bbq\",\n",
    "    \"breakfast\",\n",
    "    \"burgers\",\n",
    "    \"cafe\",\n",
    "    \"chinese\",\n",
    "    \"desserts\",\n",
    "    \"fastfood\",\n",
    "    \"french\",\n",
    "    \"greek\",\n",
    "    \"healthy\",\n",
    "    \"indian\",\n",
    "    \"italian\",\n",
    "    \"japanese\",\n",
    "    \"korean\",\n",
    "    \"latinamerican\",\n",
    "    \"mediterranean\",\n",
    "    \"mexican\",\n",
    "    \"middleeastern\",\n",
    "    \"pizza\",\n",
    "    \"salads\",\n",
    "    \"sandwiches\",\n",
    "    \"seafood\",\n",
    "    \"sushi\",\n",
    "    \"thai\",\n",
    "    \"vegan\",\n",
    "    \"vegetarian\",\n",
    "    \"vietnamese\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3484653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull consumer information from the DB\n",
    "def get_consumer_info(consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, field):\n",
    "\n",
    "\n",
    "    # Extract desired information\n",
    "    path_route = ''\n",
    "    match field:\n",
    "        case ConsumerField.VISITS:\n",
    "            path = 'visit'\n",
    "        case ConsumerField.ORDERS:\n",
    "            path = 'order'\n",
    "        case ConsumerField.FAVORITED:\n",
    "            path = 'favorited'\n",
    "        case _: # default case\n",
    "            raise HTTPException(status_code=500, detail=\"Passed in invalid consumer info field\")\n",
    "        \n",
    "    # TODO: Fix (add consumer_info & req.query)\n",
    "    response = {}\n",
    "    if is_full_address_provided:\n",
    "        params = {\n",
    "             \"street_address\": street_address,\n",
    "            \"city\": city,\n",
    "            \"postal_code\": postal_code,\n",
    "            \"state\": state,\n",
    "            \"country\": country,\n",
    "        }\n",
    "        response = requests.get(f\"{BACKEND_URL}/{path_route}/{consumer_id}\", params={params})\n",
    "    else:\n",
    "        response = requests.get(f\"{BACKEND_URL}/{path_route}/{consumer_id}\")\n",
    "    if not response.ok:\n",
    "        raise HTTPException(status_code=424, detail=\"Failed to pull consumer information from DB\")\n",
    "    selected_consumer_restaurant_data = response.json()\n",
    "    return selected_consumer_restaurant_data\n",
    "\n",
    "## Pull restaurant information from the DB\n",
    "def get_restaurant_info():\n",
    "    response = requests.get(f\"{BACKEND_URL}/restaurant\")\n",
    "    if not response.ok:\n",
    "        raise HTTPException(status_code=424, detail=\"Failed to pull restaurant information from DB\")\n",
    "    restaurants_data = response.json()\n",
    "    return restaurants_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e09bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features & Default Weights\n",
    "\n",
    "# Feature Weights\n",
    "rating_weight = 0.3; avg_cost_weight = 0.2; distance_weight = 0.125\n",
    "category_budget = 1 - rating_weight - avg_cost_weight - distance_weight\n",
    "num_categories = len(categories)\n",
    "category_weight = category_budget / num_categories\n",
    "\n",
    "feature_weights = {\n",
    "    'rating': rating_weight,\n",
    "    'avg_cost': avg_cost_weight,\n",
    "    'distance': distance_weight,\n",
    "}\n",
    "for category in categories: # Add in category feature weights\n",
    "    feature_weights[category] = category_weight\n",
    "\n",
    "# Existing Restaurant Interaction Weights\n",
    "# NOTE: Used to define how to weigh restaurant's to generate consumer vector\n",
    "# TODO: Edit later?\n",
    "restaurant_type_weights = {\n",
    "    'survey': 0.6,\n",
    "    'favorited': 0.8,\n",
    "    'order': 0.4,\n",
    "    'visit': 0.2,\n",
    "}\n",
    "\n",
    "# Consumer Vector Feedback/Interaction Weights\n",
    "# NOTE: Used to define feedback on updating consumer vector based on interactions with recommendations\n",
    "# TODO: Edit later?\n",
    "recommendation_feedback_weights = {\n",
    "    'favorited': 0.2,\n",
    "    'order': 0.1,\n",
    "    'visit': 0.04,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "# Winsorization is used to solve min-max normalization isues caused by outliers by taking, say, the 1st percentile & 99th percentile rather than min & max\n",
    "# Resource: https://medium.com/@whyamit404/implementing-pandas-winsorize-ad1e51ec548b\n",
    "def winsorization(arr):\n",
    "    np_arr = np.array(arr)\n",
    "\n",
    "    winsorized_min = np.percentile(np_arr, 1)\n",
    "    winsorized_max = np.percentile(np_arr, 99)\n",
    "\n",
    "    return [winsorized_min, winsorized_max]\n",
    "\n",
    "# Normalization takes a vector and makes it a unit vector (magnitude one)\n",
    "# Resource: https://www.khanacademy.org/computing/computer-programming/programming-natural-simulations/programming-vectors/a/vector-magnitude-normalization\n",
    "def normalization(column_vector):\n",
    "    squared_sum = 0\n",
    "    for i in range(column_vector.shape[0]):\n",
    "        squared_sum += column_vector[i]**2\n",
    "        \n",
    "    norm = np.sqrt(squared_sum)\n",
    "    \n",
    "    for i in range(column_vector.shape[0]):\n",
    "        column_vector[i] = column_vector[i] / norm\n",
    "        \n",
    "    return column_vector\n",
    "    \n",
    "\n",
    "# Get parameters required to generate restaurant embeddings\n",
    "def get_restaurant_embedding_params(restaurants_data):\n",
    "    # Find average values (for default & normalization)\n",
    "    ratings_arr = [restaurant['avg_rating'] for restaurant in restaurants_data] # NOTE: Array composition method inspired by https://stackoverflow.com/questions/50216362/how-to-extract-from-a-json-array-in-python\n",
    "    rating_sum = sum(rating for rating in ratings_arr if (rating != -1)) # Only use ratings from restaurants w/ existing ratings\n",
    "    num_ratings = sum(1 for rating in ratings_arr if (rating != -1)) # Only count ratings from restaurants w/ existing ratings\n",
    "    avg_rating =  rating_sum / num_ratings \n",
    "\n",
    "    cost_arr = [restaurant['avg_cost'] for restaurant in restaurants_data]\n",
    "    min_winsorized_cost, max_winsorized_cost = winsorization(cost_arr)\n",
    "\n",
    "    # NOTE: Distance may not yet be populated if user hasn't entered the address they're ordering from (this approach is taken to reduce Google Maps API exhaustion)\n",
    "    distance_meters_arr = [restaurant['distance_value'] for restaurant in restaurants_data]\n",
    "    is_distance_field_valid = distance_meters_arr[0] is not None\n",
    "    avg_distance_meters = 0.5\n",
    "    min_winsorized_distance, max_winsorized_distance = None\n",
    "    if is_distance_field_valid:\n",
    "        avg_distance_meters = sum(distance_meters_arr) / len(distance_meters_arr)\n",
    "        min_winsorized_distance, max_winsorized_distance = winsorization(distance_meters_arr)\n",
    "\n",
    "    return [is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters]\n",
    "\n",
    "# Generate Vector/Embedding (Shared between Consumer & Restaurant Vector Operations)\n",
    "def generate_restaurant_embedding(restaurant, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters):\n",
    "    # Normalizing Values (NOTE: Cost & Distance are Min-Max Normalized w/ Inversion (lower cost/distance is more favorable))\n",
    "    rating_normalized = (restaurant['avg_rating'] if (restaurant['avg_rating'] != -1 ) else avg_rating) / 5.0\n",
    "    cost_normalized_inverted = 1 - ( ( restaurant['avg_cost'] - min_winsorized_cost ) / ( max_winsorized_cost - min_winsorized_cost ) ) \n",
    "    distance_normalized_inverted = avg_distance_meters\n",
    "    if is_distance_field_valid:\n",
    "        distance_normalized_inverted = 1 - ( ( restaurant['distance_value'] - min_winsorized_distance ) / ( max_winsorized_distance - min_winsorized_distance ) )\n",
    "    \n",
    "    restaurant_vector = np.array([\n",
    "        rating_normalized,\n",
    "        cost_normalized_inverted,\n",
    "        distance_normalized_inverted,\n",
    "    ])\n",
    "    # Add in category weights\n",
    "    for category in categories:\n",
    "        if(category in restaurant['categories']):\n",
    "            restaurant_vector = np.append(restaurant_vector, 1)\n",
    "        else: \n",
    "            restaurant_vector = np.append(restaurant_vector, 0)\n",
    "\n",
    "    return restaurant_vector\n",
    "\n",
    "# Uses embedding parameters to generate a dictionary of embeddings (whose keys are restaurant_id's))\n",
    "def generate_embeddings_dict(restaurants_data, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters):\n",
    "    restaurant_vectors_dict = {} # Restaurant ID to vector mappings\n",
    "    for restaurant in restaurants_data:\n",
    "        restaurant_vector = generate_restaurant_embedding(restaurant, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "        restaurant_vectors_dict[restaurant['restaurant_id']] = restaurant_vector\n",
    "    return restaurant_vectors_dict\n",
    "\n",
    "# Get the mean vector of a set of vectors\n",
    "# NOTE: For column vectors, resultant mean is a column vector where each entry is the mean of the entries of that index across the vectors\n",
    "def get_mean_vector(vectors):\n",
    "    mean_vector = np.mean(vectors, axis=1)\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restaurant Vectors Generation\n",
    "def generate_restaurant_vectors():\n",
    "    restaurants_data = get_restaurant_info()\n",
    "    is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters = get_restaurant_embedding_params(restaurants_data)\n",
    "    restaurant_vectors_dict = generate_embeddings_dict(restaurants_data, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    \n",
    "    # Normalize each restaurant vector\n",
    "    for key, vector in restaurant_vectors_dict.items():\n",
    "        normalized_vector = normalization(vector)\n",
    "        restaurant_vectors_dict[key] = normalized_vector\n",
    "        \n",
    "    return restaurant_vectors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bff3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consumer Vector Operations\n",
    "\n",
    "# Generate consumer vector if it doesn't previously exist\n",
    "def generate_init_consumer_vector(consumer_id, is_full_address_provided, street_address, city, postal_code, state, country):\n",
    "    # Embedding parameters determined at the level of all restaurants (to have consistent averages, min/max, etc)\n",
    "    restaurants_data = get_restaurant_info()\n",
    "    is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters = get_restaurant_embedding_params(restaurants_data)\n",
    "    \n",
    "    # Find mean embedding among all restaurants to fill in for missing site_visit/orders/favorited embeddings\n",
    "    # NOTE: Approach for collecting embeddings dict values into numpy matrix of column vectors borrowed largely from: https://stackoverflow.com/questions/60493932/how-to-combine-column-vectors-into-a-matrix\n",
    "    restaurant_vectors_dict = generate_restaurant_vectors()\n",
    "    restaurant_columns_matrix = np.column_stack([restaurant_vectors_dict[key] for key in restaurant_vectors_dict.keys()])\n",
    "    mean_restaurant_vector = get_mean_vector(restaurant_columns_matrix)\n",
    "    \n",
    "    # Retrieve consumer restaurant information\n",
    "    restaurant_site_visits = get_consumer_info(consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.VISITS)\n",
    "    restaurant_orders = get_consumer_info(consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.ORDERS)\n",
    "    restaurant_favorited = get_consumer_info(consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.FAVORITED)\n",
    "    \n",
    "    # Check consumer restaurant information for emptiness\n",
    "    is_visits_valid = (len(restaurant_site_visits) != 0)\n",
    "    is_orders_valid = (len(restaurant_orders) != 0)\n",
    "    is_favorited_valid = (len(restaurant_favorited) != 0)\n",
    "    \n",
    "    # Generate site visits embeddings (if non-empty)\n",
    "    site_visit_restaurant_vectors_dict = {}\n",
    "    order_restaurant_vectors_dict = {}\n",
    "    favorite_restaurant_vectors_dict = {}\n",
    "    if is_visits_valid:\n",
    "        site_visit_restaurant_vectors_dict = generate_embeddings_dict(restaurant_site_visits, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    if is_orders_valid:\n",
    "        order_restaurant_vectors_dict = generate_embeddings_dict(restaurant_orders, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    if is_favorited_valid:\n",
    "        favorite_restaurant_vectors_dict = generate_embeddings_dict(restaurant_favorited, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "\n",
    "    # Get mean vectors (or set mean vector to global mean vector if data was empty)\n",
    "    site_visit_mean_vector = mean_restaurant_vector\n",
    "    order_mean_vector = mean_restaurant_vector\n",
    "    favorite_mean_vector = mean_restaurant_vector\n",
    "    if is_visits_valid: \n",
    "        site_visit_columns_matrix = np.column_stack([site_visit_restaurant_vectors_dict[key] for key in site_visit_restaurant_vectors_dict.keys()])\n",
    "        site_visit_mean_vector = get_mean_vector(site_visit_columns_matrix)\n",
    "    if is_orders_valid:\n",
    "        order_columns_matrix = np.column_stack([order_restaurant_vectors_dict[key] for key in order_restaurant_vectors_dict.keys()])\n",
    "        order_mean_vector = get_mean_vector(order_columns_matrix)\n",
    "    if is_favorited_valid:\n",
    "        favorite_columns_matrix = np.column_stack([favorite_restaurant_vectors_dict[key] for key in favorite_restaurant_vectors_dict.keys()])\n",
    "        favorite_mean_vector = get_mean_vector(favorite_columns_matrix)\n",
    "\n",
    "    # Get consumer vector (weighted average of mean vectors)\n",
    "    init_consumer_vector = (restaurant_type_weights['visit'] * site_visit_mean_vector +\n",
    "                            restaurant_type_weights['order'] * order_mean_vector +\n",
    "                            restaurant_type_weights['favorited'] * favorite_mean_vector)\n",
    "\n",
    "    # Normalize consumer vector\n",
    "    normalized_init_consumer_vector = normalization(init_consumer_vector)\n",
    "\n",
    "    return normalized_init_consumer_vector\n",
    "\n",
    "# Update consumer vector based on user interactions with recommendations\n",
    "def update_consumer_vector():\n",
    "    # TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cosine similarity\n",
    "# TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec83cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return top-N recommendations\n",
    "# TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/recommend/{consumer_id}\")\n",
    "def recommend(consumer_id: int, street_address: str | None = None, city: str | None = None, postal_code: str | None = None, state: str | None = None, country: str | None = None):\n",
    "    # TODO: check this\n",
    "    is_address_provided = any(address_arg is not None in [street_address, city, postal_code, state, country])\n",
    "    is_full_address_provided = all(address_arg is not None in [street_address, city, postal_code, state, country])\n",
    "    if is_address_provided and  not is_full_address_provided:\n",
    "        raise HTTPException(status_code=400, detail=\"Missing some address fields\")\n",
    "        \n",
    "    \n",
    "    # TODO: Recommendation code to be called here\n",
    "    # TODO: Add consumer_id & address arguments & is_full_address_provided as argument that propagates down to generate_init_consumer_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
