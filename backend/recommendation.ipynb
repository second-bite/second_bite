{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40ab7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fastapi in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (0.35.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (1.6.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from fastapi) (0.47.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from fastapi) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from fastapi) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from uvicorn) (0.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/oscarportillo/Library/Python/3.12/lib/python/site-packages (from requests) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Installation\n",
    "%pip install fastapi uvicorn nest-asyncio   # API\n",
    "%pip install numpy                          # Efficient data handling\n",
    "%pip install python-dotenv                  # .env => extracting hidden info\n",
    "%pip install requests                       # Performing API calls\n",
    "\n",
    "## Imports\n",
    "from fastapi import FastAPI, Cookie, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from typing import Annotated\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93af02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "load_dotenv()\n",
    "\n",
    "## Global Variables\n",
    "BACKEND_URL = os.getenv(\"BACKEND_URL\")\n",
    "class ConsumerField(Enum):\n",
    "    VISITS = 1\n",
    "    ORDERS = 2\n",
    "    FAVORITED = 3\n",
    "    FRIENDS = 4\n",
    "    ALL = 5\n",
    "\n",
    "categories = [ # Based off of prisma schema categories enum\n",
    "    \"asian\",\n",
    "    \"bakery\",\n",
    "    \"barfood\",\n",
    "    \"bbq\",\n",
    "    \"breakfast\",\n",
    "    \"burgers\",\n",
    "    \"cafe\",\n",
    "    \"chinese\",\n",
    "    \"desserts\",\n",
    "    \"fastfood\",\n",
    "    \"french\",\n",
    "    \"greek\",\n",
    "    \"healthy\",\n",
    "    \"indian\",\n",
    "    \"italian\",\n",
    "    \"japanese\",\n",
    "    \"korean\",\n",
    "    \"latinamerican\",\n",
    "    \"mediterranean\",\n",
    "    \"mexican\",\n",
    "    \"middleeastern\",\n",
    "    \"pizza\",\n",
    "    \"salads\",\n",
    "    \"sandwiches\",\n",
    "    \"seafood\",\n",
    "    \"sushi\",\n",
    "    \"thai\",\n",
    "    \"vegan\",\n",
    "    \"vegetarian\",\n",
    "    \"vietnamese\",\n",
    "]\n",
    "\n",
    "# Number of restaurants to recommend. NOTE: Will be less if < NUM_RECOMMENDATIONS restaurants stored in DB\n",
    "NUM_RECOMMENDATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990f40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\", \"http://localhost:3000\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3484653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull consumer information from the DB\n",
    "def get_consumer_info(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, field):\n",
    "    # Extract desired information\n",
    "    path_route = ''\n",
    "    match field:\n",
    "        case ConsumerField.VISITS:\n",
    "            path_route = 'visit'\n",
    "        case ConsumerField.ORDERS:\n",
    "            path_route = 'order'\n",
    "        case ConsumerField.FAVORITED:\n",
    "            path_route = 'favorited'\n",
    "        case _: # default case\n",
    "            raise HTTPException(status_code=500, detail=\"Passed in invalid consumer info field\")\n",
    "    \n",
    "    # Fetch consumer's specific restaurant information from DB\n",
    "    cookies = {\n",
    "        \"connect.sid\": connect_sid\n",
    "    }\n",
    "    response = {}\n",
    "    if is_full_address_provided:\n",
    "        params = {\n",
    "             \"street_address\": street_address,\n",
    "            \"city\": city,\n",
    "            \"postal_code\": postal_code,\n",
    "            \"state\": state,\n",
    "            \"country\": country,\n",
    "        }\n",
    "        response = requests.get(f\"{BACKEND_URL}/restaurant/{path_route}/{consumer_id}\", params=params, cookies=cookies)\n",
    "    else:\n",
    "        response = requests.get(f\"{BACKEND_URL}/restaurant/{path_route}/{consumer_id}\", cookies=cookies)\n",
    "    if not response.ok:\n",
    "        raise HTTPException(status_code=424, detail=\"Failed to pull consumer information from DB\")\n",
    "    selected_consumer_restaurant_data = response.json()\n",
    "    return selected_consumer_restaurant_data\n",
    "\n",
    "## Pull restaurant information from the DB\n",
    "def get_restaurant_info(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country):\n",
    "    response = {}\n",
    "    cookies = {\n",
    "        \"connect.sid\": connect_sid\n",
    "    }\n",
    "    if is_full_address_provided:\n",
    "        params = {\n",
    "            \"street_address\": street_address,\n",
    "            \"city\": city,\n",
    "            \"postal_code\": postal_code,\n",
    "            \"state\": state,\n",
    "            \"country\": country,\n",
    "        }\n",
    "        response = requests.get(f\"{BACKEND_URL}/restaurant\", params=params, cookies=cookies)\n",
    "    else: \n",
    "        response = requests.get(f\"{BACKEND_URL}/restaurant\", cookies=cookies)\n",
    "    if not response.ok:\n",
    "        raise HTTPException(status_code=424, detail=\"Failed to pull restaurant information from DB\")\n",
    "    restaurants_data = response.json()\n",
    "    return restaurants_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e09bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features & Default Weights\n",
    "\n",
    "# Feature Weights\n",
    "rating_weight = 0.3; avg_cost_weight = 0.2; distance_weight = 0.125\n",
    "category_budget = 1 - rating_weight - avg_cost_weight - distance_weight\n",
    "num_categories = len(categories)\n",
    "category_weight = category_budget / num_categories\n",
    "\n",
    "feature_weights = {\n",
    "    'rating': rating_weight,\n",
    "    'avg_cost': avg_cost_weight,\n",
    "    'distance': distance_weight,\n",
    "}\n",
    "for category in categories: # Add in category feature weights\n",
    "    feature_weights[category] = category_weight\n",
    "\n",
    "feature_weights_vector = np.array([ feature_weights[feature] for feature in feature_weights.keys() ])\n",
    "\n",
    "# Existing Restaurant Interaction Weights\n",
    "# NOTE: Used to define how to weigh restaurant's to generate consumer vector\n",
    "# TODO: Edit later?\n",
    "restaurant_type_weights = {\n",
    "    'survey': 0.6,\n",
    "    'favorited': 0.8,\n",
    "    'order': 0.4,\n",
    "    'visit': 0.2,\n",
    "}\n",
    "\n",
    "# Consumer Vector Feedback/Interaction Weights\n",
    "# NOTE: Used to define feedback on updating consumer vector based on interactions with recommendations\n",
    "# TODO: Edit later?\n",
    "recommendation_feedback_weights = {\n",
    "    'favorited': 0.2,\n",
    "    'order': 0.1,\n",
    "    'visit': 0.04,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b024ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "# Winsorization is used to solve min-max normalization isues caused by outliers by taking, say, the 1st percentile & 99th percentile rather than min & max\n",
    "# Resource: https://medium.com/@whyamit404/implementing-pandas-winsorize-ad1e51ec548b\n",
    "def winsorization(arr):\n",
    "    np_arr = np.array(arr)\n",
    "\n",
    "    winsorized_min = np.percentile(np_arr, 1)\n",
    "    winsorized_max = np.percentile(np_arr, 99)\n",
    "\n",
    "    return [winsorized_min, winsorized_max]\n",
    "\n",
    "# Normalization takes a vector and makes it a unit vector (magnitude one)\n",
    "# Resource: https://www.khanacademy.org/computing/computer-programming/programming-natural-simulations/programming-vectors/a/vector-magnitude-normalization\n",
    "def normalization(column_vector):\n",
    "    squared_sum = 0\n",
    "    for i in range(column_vector.shape[0]):\n",
    "        squared_sum += column_vector[i]**2\n",
    "        \n",
    "    norm = np.sqrt(squared_sum)\n",
    "    \n",
    "    if norm == 0:\n",
    "        return column_vector\n",
    "    \n",
    "    for i in range(column_vector.shape[0]):\n",
    "        column_vector[i] = column_vector[i] / norm\n",
    "        \n",
    "    return column_vector\n",
    "    \n",
    "\n",
    "# Get parameters required to generate restaurant embeddings\n",
    "def get_restaurant_embedding_params(restaurants_data):\n",
    "    # Find average values (for default & normalization)\n",
    "    ratings_arr = [restaurant['avg_rating'] for restaurant in restaurants_data] # NOTE: Array composition method inspired by https://stackoverflow.com/questions/50216362/how-to-extract-from-a-json-array-in-python\n",
    "    rating_sum = sum(rating for rating in ratings_arr if (rating != -1)) # Only use ratings from restaurants w/ existing ratings\n",
    "    num_ratings = sum(1 for rating in ratings_arr if (rating != -1)) # Only count ratings from restaurants w/ existing ratings\n",
    "    avg_rating =  rating_sum / num_ratings \n",
    "\n",
    "    cost_arr = [float(restaurant['avg_cost']) for restaurant in restaurants_data]\n",
    "    min_winsorized_cost, max_winsorized_cost = winsorization(cost_arr)\n",
    "\n",
    "    # NOTE: Distance may not yet be populated if user hasn't entered the address they're ordering from (this approach is taken to reduce Google Maps API exhaustion)\n",
    "    distance_meters_arr = [restaurant['distance_value'] for restaurant in restaurants_data]\n",
    "    is_distance_field_valid = distance_meters_arr[0] is not None # NOTE: Distance field is either populated for all or none\n",
    "    avg_distance_meters = 0.5\n",
    "    min_winsorized_distance = max_winsorized_distance = None\n",
    "    if is_distance_field_valid:\n",
    "        avg_distance_meters = sum(distance_meters_arr) / len(distance_meters_arr)\n",
    "        min_winsorized_distance, max_winsorized_distance = winsorization(distance_meters_arr)\n",
    "\n",
    "    return [is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters]\n",
    "\n",
    "# Generate Vector/Embedding (Shared between Consumer & Restaurant Vector Operations)\n",
    "def generate_restaurant_embedding(restaurant, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters):\n",
    "    # Normalizing Values (NOTE: Cost & Distance are Min-Max Normalized w/ Inversion (lower cost/distance is more favorable))\n",
    "    rating_normalized = (restaurant['avg_rating'] if (restaurant['avg_rating'] != -1 ) else avg_rating) / 5.0\n",
    "    cost_normalized_inverted = 1 - ( ( float(restaurant['avg_cost']) - min_winsorized_cost ) / ( max_winsorized_cost - min_winsorized_cost ) ) \n",
    "    distance_normalized_inverted = avg_distance_meters\n",
    "    if is_distance_field_valid:\n",
    "        distance_normalized_inverted = 1 - ( ( restaurant['distance_value'] - min_winsorized_distance ) / ( max_winsorized_distance - min_winsorized_distance ) )\n",
    "    \n",
    "    restaurant_vector = np.array([\n",
    "        rating_normalized,\n",
    "        cost_normalized_inverted,\n",
    "        distance_normalized_inverted,\n",
    "    ])\n",
    "    # Add in category weights\n",
    "    for category in categories:\n",
    "        if(category in restaurant['categories']):\n",
    "            restaurant_vector = np.append(restaurant_vector, 1)\n",
    "        else: \n",
    "            restaurant_vector = np.append(restaurant_vector, 0)\n",
    "    \n",
    "    # Apply feature weights\n",
    "    restaurant_vector = restaurant_vector * feature_weights_vector\n",
    "\n",
    "    return restaurant_vector\n",
    "\n",
    "# Uses embedding parameters to generate a dictionary of embeddings (whose keys are restaurant_id's))\n",
    "def generate_embeddings_dict(restaurants_data, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters):\n",
    "    restaurant_vectors_dict = {} # Restaurant ID to vector mappings\n",
    "    for restaurant in restaurants_data:\n",
    "        restaurant_vector = generate_restaurant_embedding(restaurant, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "        restaurant_vectors_dict[restaurant['restaurant_id']] = restaurant_vector\n",
    "    return restaurant_vectors_dict\n",
    "\n",
    "# Get the mean vector of a set of vectors\n",
    "# NOTE: For column vectors, resultant mean is a column vector where each entry is the mean of the entries of that index across the vectors\n",
    "def get_mean_vector(vectors):\n",
    "    mean_vector = np.mean(vectors, axis=1)\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa9cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restaurant Vectors Generation\n",
    "def generate_restaurant_vectors(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country):\n",
    "    restaurants_data = get_restaurant_info(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters = get_restaurant_embedding_params(restaurants_data)\n",
    "    restaurant_vectors_dict = generate_embeddings_dict(restaurants_data, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    \n",
    "    # Normalize each restaurant vector\n",
    "    for key, vector in restaurant_vectors_dict.items():\n",
    "        normalized_vector = normalization(vector)\n",
    "        restaurant_vectors_dict[key] = normalized_vector\n",
    "        \n",
    "    return restaurant_vectors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bff3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consumer Vector Operations\n",
    "\n",
    "# Generate consumer vector if it doesn't previously exist\n",
    "def generate_init_consumer_vector(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country):\n",
    "    # Embedding parameters determined at the level of all restaurants (to have consistent averages, min/max, etc)\n",
    "    restaurants_data = get_restaurant_info(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters = get_restaurant_embedding_params(restaurants_data)\n",
    "    \n",
    "    # Find mean embedding among all restaurants to fill in for missing site_visit/orders/favorited embeddings\n",
    "    # NOTE: Approach for collecting embeddings dict values into numpy matrix of column vectors borrowed largely from: https://stackoverflow.com/questions/60493932/how-to-combine-column-vectors-into-a-matrix\n",
    "    restaurant_vectors_dict = generate_restaurant_vectors(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    restaurant_columns_matrix = np.column_stack([restaurant_vectors_dict[key] for key in restaurant_vectors_dict.keys()])\n",
    "    mean_restaurant_vector = get_mean_vector(restaurant_columns_matrix)\n",
    "    mean_restaurant_vector = normalization(mean_restaurant_vector)\n",
    "    \n",
    "    # Retrieve consumer restaurant information\n",
    "    restaurant_site_visits = get_consumer_info(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.VISITS)\n",
    "    restaurant_orders = get_consumer_info(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.ORDERS)\n",
    "    restaurant_favorited = get_consumer_info(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country, ConsumerField.FAVORITED)\n",
    "    \n",
    "    # Check consumer restaurant information for emptiness\n",
    "    is_visits_valid = (len(restaurant_site_visits) != 0)\n",
    "    is_orders_valid = (len(restaurant_orders) != 0)\n",
    "    is_favorited_valid = (len(restaurant_favorited) != 0)\n",
    "    \n",
    "    # Generate site visits embeddings (if non-empty)\n",
    "    site_visit_restaurant_vectors_dict = {}\n",
    "    order_restaurant_vectors_dict = {}\n",
    "    favorite_restaurant_vectors_dict = {}\n",
    "    if is_visits_valid:\n",
    "        site_visit_restaurant_vectors_dict = generate_embeddings_dict(restaurant_site_visits, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    if is_orders_valid:\n",
    "        order_restaurant_vectors_dict = generate_embeddings_dict(restaurant_orders, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "    if is_favorited_valid:\n",
    "        favorite_restaurant_vectors_dict = generate_embeddings_dict(restaurant_favorited, is_distance_field_valid, min_winsorized_cost, max_winsorized_cost, min_winsorized_distance, max_winsorized_distance, avg_rating, avg_distance_meters)\n",
    "\n",
    "    # Get mean vectors (or set mean vector to global mean vector if data was empty)\n",
    "    site_visit_mean_vector = mean_restaurant_vector\n",
    "    order_mean_vector = mean_restaurant_vector \n",
    "    favorite_mean_vector = mean_restaurant_vector\n",
    "    if is_visits_valid: \n",
    "        site_visit_columns_matrix = np.column_stack([normalization(site_visit_restaurant_vectors_dict[key]) for key in site_visit_restaurant_vectors_dict.keys()])\n",
    "        site_visit_mean_vector = get_mean_vector(site_visit_columns_matrix)\n",
    "        site_visit_mean_vector = normalization(site_visit_mean_vector)\n",
    "    if is_orders_valid:\n",
    "        order_columns_matrix = np.column_stack([normalization(order_restaurant_vectors_dict[key]) for key in order_restaurant_vectors_dict.keys()])\n",
    "        order_mean_vector = get_mean_vector(order_columns_matrix)\n",
    "        order_mean_vector = normalization(order_mean_vector)\n",
    "    if is_favorited_valid:\n",
    "        favorite_columns_matrix = np.column_stack([normalization(favorite_restaurant_vectors_dict[key]) for key in favorite_restaurant_vectors_dict.keys()])\n",
    "        favorite_mean_vector = get_mean_vector(favorite_columns_matrix)\n",
    "        favorite_mean_vector = normalization(favorite_mean_vector)\n",
    "\n",
    "    # Get consumer vector (weighted average of mean vectors)\n",
    "    weight_visit = restaurant_type_weights['visit'] if is_visits_valid else 0.0\n",
    "    weight_order = restaurant_type_weights['order'] if is_orders_valid else 0.0\n",
    "    weight_fav   = restaurant_type_weights['favorited'] if is_favorited_valid else 0.0\n",
    "    init_consumer_vector = None\n",
    "    if (weight_visit + weight_order + weight_fav) == 0:\n",
    "        init_consumer_vector = mean_restaurant_vector\n",
    "    else: \n",
    "        init_consumer_vector = (weight_visit * site_visit_mean_vector +\n",
    "                                weight_order * order_mean_vector +\n",
    "                                weight_fav * favorite_mean_vector)\n",
    "    \n",
    "    # Normalize consumer vector\n",
    "    normalized_init_consumer_vector = normalization(init_consumer_vector)\n",
    "\n",
    "    return normalized_init_consumer_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce17c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cosine similarity\n",
    "# NOTE: Inspired by https://datastax.medium.com/how-to-implement-cosine-similarity-in-python-505e8ec1d823\n",
    "def cosine_similarity(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country):\n",
    "    restaurant_vectors_dict = generate_restaurant_vectors(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    consumer_vector = generate_init_consumer_vector(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    \n",
    "    restaurant_similarity_dict = {}\n",
    "    for restaurant_id, restaurant_vector in restaurant_vectors_dict.items():\n",
    "        # Check, just in case\n",
    "        if(consumer_vector.shape != restaurant_vector.shape):\n",
    "            raise HTTPException(status_code=400, detail=\"Consumer and restaurant vector shapes aren't the same\")\n",
    "        if(consumer_vector.ndim != 1 or restaurant_vector.ndim != 1):\n",
    "            raise HTTPException(status_code=400, detail=\"Either/or consumer and restaurant vector shapes aren't a 1D column vector\")\n",
    "        \n",
    "        # Dot Product\n",
    "        dot_product = np.sum(consumer_vector * restaurant_vector)\n",
    "        \n",
    "        # Find Magnitudes\n",
    "        consumer_squared_sum = restaurant_squared_sum = 0\n",
    "        for i in range(consumer_vector.shape[0]):\n",
    "            consumer_squared_sum += consumer_vector[i]**2\n",
    "            restaurant_squared_sum += restaurant_vector[i]**2\n",
    "        consumer_vector_magnitude = np.sqrt(consumer_squared_sum)\n",
    "        restaurant_vector_magnitude = np.sqrt(restaurant_squared_sum)\n",
    "        \n",
    "        # Cosine Similarity Formula\n",
    "        cosine_similarity_val = dot_product / (consumer_vector_magnitude * restaurant_vector_magnitude)\n",
    "        \n",
    "        restaurant_similarity_dict[restaurant_id] = cosine_similarity_val\n",
    "        \n",
    "    return restaurant_similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec83cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return top-N recommendations\n",
    "# TODO: \n",
    "def top_n_recommendations(restaurant_similarity_dict, num_recommendations):\n",
    "    # Sorting inspired by: https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "    restaurant_similarity_dict = dict(sorted(restaurant_similarity_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    if(len(restaurant_similarity_dict) < num_recommendations):\n",
    "        top_n_restaurant_similarity_dict = list(restaurant_similarity_dict.items())\n",
    "        return top_n_restaurant_similarity_dict\n",
    "    else:\n",
    "        top_n_restaurant_similarity_dict = list(restaurant_similarity_dict.items())[:num_recommendations]\n",
    "        return top_n_restaurant_similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5acd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/recommend/{consumer_id}\")\n",
    "def recommend(consumer_id: int, street_address: str | None = None, city: str | None = None, postal_code: str | None = None, state: str | None = None, country: str | None = None, connect_sid: Annotated[str | None, Cookie(alias=\"connect.sid\")] = None):\n",
    "    # NOTE: FastAPI Cookie handling from here: https://fastapi.tiangolo.com/tutorial/cookie-params/#import-cookie\n",
    "    if connect_sid is None:\n",
    "        raise HTTPException(status_code=401, detail=\"Consumer session cookie not found\")\n",
    "\n",
    "    is_address_provided = any(address_arg is not None for address_arg in [street_address, city, postal_code, state, country])\n",
    "    is_full_address_provided = all(address_arg is not None for address_arg in [street_address, city, postal_code, state, country])\n",
    "    if is_address_provided and  not is_full_address_provided:\n",
    "        raise HTTPException(status_code=400, detail=\"Missing some address fields\")\n",
    "        \n",
    "    # Recommendation\n",
    "    restaurant_similarity_dict = cosine_similarity(connect_sid, consumer_id, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    top_n_restaurant_similarity_dict = top_n_recommendations(restaurant_similarity_dict, NUM_RECOMMENDATIONS)\n",
    "    \n",
    "    # Restaurant ID -> Restaurant Map\n",
    "    restaurants = get_restaurant_info(connect_sid, is_full_address_provided, street_address, city, postal_code, state, country)\n",
    "    id_to_restaurant_map = {restaurant['restaurant_id']: restaurant for restaurant in restaurants}\n",
    "    \n",
    "    # Cross-reference the restaurant IDs from recommendation with the restaurant objects\n",
    "    sorted_recommended_restaurants = []\n",
    "    for restaurant_id, _ in top_n_restaurant_similarity_dict:\n",
    "        if restaurant_id not in id_to_restaurant_map:\n",
    "            raise HTTPException(status_code=500, detail=\"Internal Error mapping restaurant ID to restaurant\")\n",
    "        sorted_recommended_restaurants.append(id_to_restaurant_map[restaurant_id])   \n",
    "    \n",
    "    return JSONResponse(sorted_recommended_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [20812]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57837 - \"GET /recommend/4 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57848 - \"GET /recommend/4 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58008 - \"GET /recommend/4?street_address=1%20Hacker%20Way&city=Menlo%20Park&postal_code=94025&state=CA&country=US HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "## Get FastAPI Server Online\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
